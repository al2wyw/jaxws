基础知识:
对象结构:
typedef struct redisObject {
         unsigned type:4;
         unsigned encoding:4;
         unsigned lru:LRU_BITS; /* LRU time (relative to global lru_clock) or
                                 * LFU data (least significant 8 bits frequency
                                 * and most significant 16 bits access time). */
         int refcount;
         void *ptr;
     } robj;
数据类型(主要5种,每种对应2~3数据结构): string(raw, int, sds), list(zlist, qlist, llist), hash(zlist, ht), set(intset, ht), zset(sorted set)(zlist, slist), bitmaps and hyperLog(底层就是string)
数据结构:
#define OBJ_ENCODING_RAW 0     /* Raw representation */
#define OBJ_ENCODING_INT 1     /* Encoded as integer */
#define OBJ_ENCODING_HT 2      /* Encoded as hash table */
#define OBJ_ENCODING_ZIPMAP 3  /* Encoded as zipmap */
#define OBJ_ENCODING_LINKEDLIST 4 /* No longer used: old list encoding. */
#define OBJ_ENCODING_ZIPLIST 5 /* Encoded as ziplist */
#define OBJ_ENCODING_INTSET 6  /* Encoded as intset */
#define OBJ_ENCODING_SKIPLIST 7  /* Encoded as skiplist */
#define OBJ_ENCODING_EMBSTR 8  /* Embedded sds string encoding */
#define OBJ_ENCODING_QUICKLIST 9 /* Encoded as linked list of ziplists */
#define OBJ_ENCODING_STREAM 10 /* Encoded as a radix tree of listpacks */
OBJ_ENCODING_EMBSTR: 二进制安全(写入什么就读出什么,支持存储各种数据类型, 只读取len长度内容, 不像c一样不能存储\0字符), 长度获取O(1)(直接读取len字段), append防止内存溢出(free字段检查), 空间预分配&惰性回收
OBJ_ENCODING_HT: 渐进式扩容(不是一次性全部迁移)，扩容时两个数组同时存在
OBJ_ENCODING_QUICKLIST: ZIPLIST+双向链表，避免ZIPLIST扩容时大量复制操作和list过度消耗内存
OBJ_ENCODING_SKIPLIST: zset的底层实现, 按分值排序，增删查效率和红黑树一致，但范围查询比红黑树高
压缩数据结构:(连续的内存空间)
OBJ_ENCODING_ZIPLIST: 连续的内存空间，有固定的数据大小格式，通过pre-node-length可以从尾部倒序地直接定位数据内容
OBJ_ENCODING_INTSET: 数据类型升级
bitmap使用的是string类型raw编码
struct sdshdr{
    //buf已使用的字节数
    int len;
    //buf未使用的字节数
    int free;
    //字节数组，用于保存字符串
    char buf[];
}

数据库:
typedef struct redisDb {
    dict *dict;                 /* The keyspace for this DB */
    dict *expires;              /* Timeout of keys with a timeout set */
    dict *blocking_keys;        /* Keys with clients waiting for data (BLPOP)*/
    dict *ready_keys;           /* Blocked keys that received a PUSH */
    dict *watched_keys;         /* WATCHED keys for MULTI/EXEC CAS */
    int id;                     /* Database ID */
    long long avg_ttl;          /* Average TTL, just for stats */
    list *defrag_later;         /* List of key names to attempt to defrag one by one, gradually. */
} redisDb;

内存回收
- 引用计数 refcount
当创建一个新对象时，引用计数初始化为1
当调用incrRefCount时，引用计数加1
当调用decrRefCount时，引用计数减1，当引用计数为0时回收对象内存

共享对象 (对象引用计数增1)
只对整数值对象进行共享(字符串需要更复杂的比对算法，占用cpu多，所以不共享)

数据库功能:
最大内存设置(当物理内存被占满后会使用swap空间)
根据配置的数据淘汰策略尝试淘汰数据，释放空间
如果没有数据可以淘汰，或者没有配置数据淘汰策略，那么Redis会对所有写请求返回错误，但读请求仍然可以正常执行
如果采用了Redis的主从同步，主节点向从节点同步数据时，会占用掉一部分内存空间

数据淘汰机制
volatile-lru：使用LRU算法进行数据淘汰，只淘汰设定了有效期的key
allkeys-lru：使用LRU算法进行数据淘汰，所有的key都可以被淘汰
volatile-lfu：
allkeys-lfu：
volatile-random：随机淘汰数据，只淘汰设定了有效期的key
allkeys-random：随机淘汰数据，所有的key都可以被淘汰
volatile-ttl：淘汰剩余有效期最短的key


过期数据实现
redisDb结构的expires指向拥有过期时间的key
过期数据清理
- 定期清除(数据量大时cpu占用大)
- 惰性清除(数据量大时空间占用大)
- 定频定时长清除
清除策略: 定频定时长清除(保证cpu占用率低) + 惰性清除
AOF,RDB,主从复制对过期数据处理: 全部转换成DEL操作，从库不会对key进行过期处理

RDB实现:
- SAVE 进程阻塞，等待数据全部保存完毕
- BGSAVE fork子进程，主进程不阻塞
配置间隙性SAVE(其实是BGSAVE)

AOF实现: 处理文件消息(IO) -> 处理事件消息(serverCron) -> AOF缓存是否刷盘
- always
- every second
- no
AOF重写
CLIENT实现: 读取缓冲区， 写入缓冲区
SERVER实现: 命令执行过程 (前置处理 -> 执行命令(写入client缓冲区) -> 后置处理(写入AOF缓存等等))

集群功能:
主从模式
- 全量复制
- 增量复制

心跳检测:
在命令传播阶段，从服务器1次/s发送REPLCONF ACK <replication_offset(复制偏移量)>命令给主服务器:
检测主从网络状态
实现min-slaves-*功能
检查数据一致

防止脑裂: (两个配置项限制主库对请求的处理)
min-slaves-to-write: 主库能进行数据同步的最少从库数量
min-slaves-max-lag: 主从库间进行数据复制时，从库给主库发送ACK消息的最大延迟

哨兵模式(主从模式的HA版本，由哨兵集群来进行选举并通知客户端)
故障检测:
sentinel主观下线(主节点被判断为下线)
sentinel客观下线(收集其他sentinel节点的数据，主节点被判断为真实下线)
sentinel选举领头(选举执行故障转移的sentinel节点)
故障转移:
sentinel节点会根据优先级排序，相同则选偏移量最大的，相同则选运行ID最小的从节点

集群模式
partition的问题:
- 多key操作不支持，就算 slot 在同一个node也不支持
- 事务包含的key在不同node上不支持
只要有一个主节点down掉，整个集群状态会变成fail，无法服务(挂掉的主节点有从节点的话集群可以恢复服务，
非挂掉的主节点停服的时间短，挂掉的主节点停服的时间长)，如果主从一起挂掉，集群不可用
nodeTime可以控制slave 接管master的时间
slave端的 expire 实现: master发送del到slave

普通的hash算法是对节点数进行取模，而一致性hash是对固定值 2^32 进行取模，从而避免在扩容缩容时大量的数据rehash
一致性hash(hash cycle): 1. 使用虚拟节点避免数据倾斜 2. 数据迁移时减少需要迁移的机器节点 3. 通过计算节点的hash值从而分配在2^32的hash圆环上，无法很好的控制数据分布(节点位置分布)
redis hash(hash slot): 每个节点分配对应的slot(可以精准控制分布)，使用去中心化的p2p设计，每个节点都保存完整的slot表，可以转发客户端的请求到对应的节点
节点A  0－5460
节点B  5461－10922
节点C  10923－16383

节点A  1365-5460
节点B  6827-10922
节点C  12288-16383
节点D  0-1364,5461-6826,10923-1228

集群重定向
MOVED重定向(客户端连接重定向的节点并重新发送请求)
ASK重定向(重新分片数据迁移时的重定向)

故障检测:
集群中的节点会定期向其他的节点发送ping消息，如果接收方在规定时间内没有返回pong消息，则会被标记为pfail，集群中的节点通过ping/pong来交换节点状态
如果集群里超过半数的主节点都把某个主节点标记为pfail，则会被标记为fail，把此主节点标记为fail的主节点会广播fail消息
故障转移:
所有的从节点中选举一个新主节点
新主节点更新自己的node相关信息，广播一条pong消息，其他节点知道新的主节点信息
新主机选举:(raft的领头选举)
从节点广播一条REQUEST消息要求进行选举，任何一个未投票的主节点都可以进行响应，从节点收到的响应超过N/2+1则选举成功
如果没有从节点收到足够多的响应，则配置纪元+1，重新发起投票

集群消息:
1. meet: 接收到meet消息的节点会加入发送节点的集群
2. ping: 从节点中随机选取5个节点，并向最长没有发送ping的节点发送一个ping消息，同时也会给超过cluster-node-timeout时间一半的没有发送ping的节点发送ping消息
3. pong: 响应meet和ping消息，或者在故障转移后广播pong消息
4. fail: 当一个主节点判断另一个主节点fail时，广播fail消息，接收到消息的节点把相应节点标记为fail
5. publish: 当节点接收到publish命令时会执行这个命令同时广播一条publish消息，接收到消息的节点也会执行这条publish命令
1,2,3为gossip协议

ping/pong实现: 从已知节点随机选取两个节点信息，发送ping消息给接收方:
1. 如果两个节点是未知节点，接收方根据gossip消息的内容进行握手
2. 如果两个节点是已知节点，接收方根据gossip消息的内容更新自己的cluster node信息
接收方从已知节点随机选取两个节点信息返回pong消息给发送方

fail实现: gossip消息太慢，直接向所有节点广播fail消息，fail消息只需要携带fail的节点标识

发布与订阅:
- 频道的订阅 subscribe channelName
- 模式的订阅 subscribe channelName*

redis事务multi 不是常规的事务实现，就是多个命令一起发送到服务端执行，不保证原子性
